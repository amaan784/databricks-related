{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bcebf18-d189-4d59-aeb9-650b7c1691bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Use Langchain to interact with a SQL database \n",
    "\n",
    "The following code showcases an example of the Databricks SQL Agent. With the Databricks SQL agent any Databricks users can interact with a specified schema in Databrick Unity Catalog and generate insights on their data.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- To use this notebook, please provide your OpenAI API Token.\n",
    "- Databricks Runtime 13.3 ML and above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8ee29e2-90ce-4d73-8e2d-2f4f890474ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**SOURCE: https://docs.databricks.com/en/large-language-models/langchain.html**  \n",
    "\n",
    "The example mentioned in the notebook has outdated packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de57ee6e-8492-4a39-a186-5bfe6c530456",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Imports and checking of versions of libraries and environment\n",
    "\n",
    "Databricks recommends the latest version of `langchain` and the `databricks-sql-connector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3d3613a-dc5e-4903-8720-e596c35b89e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: openai in /databricks/python3/lib/python3.11/site-packages (1.29.0)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/99/ae/e8fb328fc0fc20ae935950b1f7160de8e2631a5997c2398c9b8a8cc502f8/openai-1.44.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/47/e7/5d88031cd743c62199b125181a591b1671df3ff2f6e102df85c58d8f7d31/jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.11/site-packages (from openai) (1.10.6)\n",
      "Requirement already satisfied: sniffio in /databricks/python3/lib/python3.11/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Obtaining dependency information for typing-extensions<5,>=4.11 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /databricks/python3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/367.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/319.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, jiter, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.29.0\n",
      "    Not uninstalling openai at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'openai'. No files were found to uninstall.\n",
      "Successfully installed jiter-0.5.0 openai-1.44.0 typing-extensions-4.12.2\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cef79e7-9169-409b-905b-c96f9c3f6939",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: sqlalchemy in /databricks/python3/lib/python3.11/site-packages (1.4.39)\n",
      "Collecting sqlalchemy\n",
      "  Obtaining dependency information for sqlalchemy from https://files.pythonhosted.org/packages/b0/33/0806c5fc85bc022b6250313a01e4e504a1f5c12fe5e48ab52d0b4c2c0f81/SQLAlchemy-2.0.34-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.34-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.11/site-packages (from sqlalchemy) (2.0.1)\n",
      "Downloading SQLAlchemy-2.0.34-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/3.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.39\n",
      "    Not uninstalling sqlalchemy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'SQLAlchemy'. No files were found to uninstall.\n",
      "Successfully installed sqlalchemy-2.0.34\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20dfe470-341b-48fc-8c43-57f68bd5fef6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: langchain in /databricks/python3/lib/python3.11/site-packages (0.1.20)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/0d/29/635343c0d155997569b544d26da5a2a9ebade2423baffc9cd6066b01a386/langchain-0.2.16-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sql-connector\n",
      "  Obtaining dependency information for databricks-sql-connector from https://files.pythonhosted.org/packages/9c/b1/0a4b9f376717d28b30a1d3d5de4dfc94155e8c604c9c73a6e277a6cc64d1/databricks_sql_connector-3.4.0-py3-none-any.whl.metadata\n",
      "  Using cached databricks_sql_connector-3.4.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting langchain-openai\n",
      "  Obtaining dependency information for langchain-openai from https://files.pythonhosted.org/packages/0e/f1/12cd80e136b6bf5f498bee178084e71d48f664e5639e9cc7f900244d9f1c/langchain_openai-0.1.23-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.3.0,>=0.2.38 from https://files.pythonhosted.org/packages/1c/e4/501fbe904530dad6ed80f03b188d7602081560dd5cc0bcf0b3c51778c314/langchain_core-0.2.38-py3-none-any.whl.metadata\n",
      "  Using cached langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/8f/f3/d01591229e9d0eec1e8106ed6f9b670f299beb1c94fed4aa335afa78acb0/langchain_text_splitters-0.2.4-py3-none-any.whl.metadata\n",
      "  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /databricks/python3/lib/python3.11/site-packages (from langchain) (0.1.63)\n",
      "Requirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain) (1.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: lz4<5.0.0,>=4.0.2 in /databricks/python3/lib/python3.11/site-packages (from databricks-sql-connector) (4.3.2)\n",
      "Requirement already satisfied: oauthlib<4.0.0,>=3.1.0 in /usr/lib/python3/dist-packages (from databricks-sql-connector) (3.2.0)\n",
      "Collecting openpyxl<4.0.0,>=3.0.10 (from databricks-sql-connector)\n",
      "  Obtaining dependency information for openpyxl<4.0.0,>=3.0.10 from https://files.pythonhosted.org/packages/c0/da/977ded879c29cbd04de313843e76868e6e13408a94ed6b987245dc7c8506/openpyxl-3.1.5-py2.py3-none-any.whl.metadata\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pandas<2.3.0,>=1.2.5 in /databricks/python3/lib/python3.11/site-packages (from databricks-sql-connector) (1.5.3)\n",
      "Requirement already satisfied: pyarrow<17,>=14.0.1 in /databricks/python3/lib/python3.11/site-packages (from databricks-sql-connector) (14.0.1)\n",
      "Collecting thrift<0.21.0,>=0.16.0 (from databricks-sql-connector)\n",
      "  Using cached thrift-0.20.0-cp311-cp311-linux_x86_64.whl\n",
      "Requirement already satisfied: urllib3>=1.26 in /databricks/python3/lib/python3.11/site-packages (from databricks-sql-connector) (1.26.16)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages (from langchain-openai) (1.44.0)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Obtaining dependency information for tiktoken<1,>=0.7 from https://files.pythonhosted.org/packages/61/b4/b80d1fe33015e782074e96bbbf4108ccd283b8deea86fb43c15d18b7c351/tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.17 from https://files.pythonhosted.org/packages/d9/8c/1b060d83dfa17d422976ff85f470396430a347a87df76dc4da5048b7a980/langsmith-0.1.116-py3-none-any.whl.metadata\n",
      "  Using cached langsmith-0.1.116-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /databricks/python3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.65.0)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.0.10->databricks-sql-connector)\n",
      "  Obtaining dependency information for et-xmlfile from https://files.pythonhosted.org/packages/96/c2/3dd434b0108730014f1b96fd286040dc3bcb70066346f7e01ec2ac95865f/et_xmlfile-1.1.0-py3-none-any.whl.metadata\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<2.3.0,>=1.2.5->databricks-sql-connector) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<2.3.0,>=1.2.5->databricks-sql-connector) (2022.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: six>=1.7.2 in /usr/lib/python3/dist-packages (from thrift<0.21.0,>=0.16.0->databricks-sql-connector) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (2.4)\n",
      "Using cached langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
      "Using cached databricks_sql_connector-3.4.0-py3-none-any.whl (428 kB)\n",
      "Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_core-0.2.38-py3-none-any.whl (396 kB)\n",
      "Using cached langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.1.116-py3-none-any.whl (290 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: thrift, et-xmlfile, tiktoken, openpyxl, langsmith, databricks-sql-connector, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.5.2\n",
      "    Not uninstalling tiktoken at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'tiktoken'. No files were found to uninstall.\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.63\n",
      "    Not uninstalling langsmith at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'langsmith'. No files were found to uninstall.\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.52\n",
      "    Not uninstalling langchain-core at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'langchain-core'. No files were found to uninstall.\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.2\n",
      "    Not uninstalling langchain-text-splitters at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'langchain-text-splitters'. No files were found to uninstall.\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.20\n",
      "    Not uninstalling langchain at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82\n",
      "    Can't uninstall 'langchain'. No files were found to uninstall.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.2.38 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed databricks-sql-connector-3.4.0 et-xmlfile-1.1.0 langchain-0.2.16 langchain-core-0.2.38 langchain-openai-0.1.23 langchain-text-splitters-0.2.4 langsmith-0.1.116 openpyxl-3.1.5 thrift-0.20.0 tiktoken-0.7.0\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade langchain databricks-sql-connector langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3827dff8-9252-43df-a50e-8036c83c3b14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.44.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: langchain-openai\n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ea9b47-57c9-4b9f-922b-4dffd9a46f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.2.16\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages\n",
      "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a76e3fc-a20c-44af-901d-4de542913335",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: databricks-sql-connector\n",
      "Version: 3.4.0\n",
      "Summary: Databricks SQL Connector for Python\n",
      "Home-page: \n",
      "Author: Databricks\n",
      "Author-email: databricks-sql-connector-maintainers@databricks.com\n",
      "License: Apache-2.0\n",
      "Location: /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe5c620-a11f-44f2-b20e-9698491f7a82/lib/python3.11/site-packages\n",
      "Requires: lz4, numpy, oauthlib, openpyxl, pandas, pyarrow, requests, thrift, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show databricks-sql-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3af1740f-8992-4131-a1f0-3f4b492aa205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "print(\"Python version:\", sys.version)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e697671-0d92-4877-a035-944b09ce0fce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name: Amaan S's Cluster\n",
      "Cluster Version: 15.3.x-cpu-ml-scala2.12\n"
     ]
    }
   ],
   "source": [
    "# Display the cluster name\n",
    "print(\"Cluster Name:\", spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\"))\n",
    "\n",
    "# Display the Databricks Runtime version of the cluster\n",
    "print(\"Cluster Version:\", spark.conf.get(\"spark.databricks.clusterUsageTags.sparkVersion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5a33961-af89-435e-aa02-da4a0c50f9c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "807765a4-0ea2-4bb2-8cdd-6bd0a0d24598",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed5ff718-df55-45d2-8136-c00aba12a172",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### SQL Database Agent\n",
    "\n",
    "This is an example of how to interact with a certain schema in Unity Catalog. Please note that the agent can't create new tables or delete tables. It can only query tables.\n",
    "\n",
    "The database instance is created within:\n",
    "```\n",
    "db = SQLDatabase.from_databricks(catalog=\"...\", schema=\"...\")\n",
    "```\n",
    "And the agent (and the required tools) are created by:\n",
    "```\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "agent = create_sql_agent(llm=llm, toolkit=toolkit, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28411def-ec17-4646-9672-8753d676b924",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be390c3-ac8d-4741-87ea-cc3dded92e90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "db = SQLDatabase.from_databricks(catalog=\"samples\", schema=\"nyctaxi\")\n",
    "llm = OpenAI(temperature=.7)\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "agent = create_sql_agent(llm=llm, toolkit=toolkit, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "762d7b5a-e787-4c36-a2ce-bf1b43c5d523",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m We need to find the longest trip distance and its duration.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT MAX(trip_distance), duration FROM trips\u001b[0m\u001b[36;1m\u001b[1;3mError: (databricks.sql.exc.ServerOperationError) [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `duration` cannot be resolved. Did you mean one of the following? [`fare_amount`, `pickup_zip`, `dropoff_zip`, `trip_distance`, `tpep_pickup_datetime`]. SQLSTATE: 42703; line 1 pos 27\n",
      "[SQL: SELECT MAX(trip_distance), duration FROM trips]\n",
      "(Background on this error at: https://sqlalche.me/e/20/4xp6)\u001b[0m\u001b[32;1m\u001b[1;3mThere is no 'duration' column in the 'trips' table.\n",
      "Action: sql_db_schema\n",
      "Action Input: trips\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE trips (\n",
      "\ttpep_pickup_datetime TIMESTAMP, \n",
      "\ttpep_dropoff_datetime TIMESTAMP, \n",
      "\ttrip_distance FLOAT, \n",
      "\tfare_amount FLOAT, \n",
      "\tpickup_zip INT, \n",
      "\tdropoff_zip INT\n",
      ") USING DELTA\n",
      "TBLPROPERTIES('delta.feature.allowColumnDefaults' = 'enabled')\n",
      "\n",
      "/*\n",
      "3 rows from trips table:\n",
      "tpep_pickup_datetime\ttpep_dropoff_datetime\ttrip_distance\tfare_amount\tpickup_zip\tdropoff_zip\n",
      "2016-02-14 16:52:13+00:00\t2016-02-14 17:16:04+00:00\t4.94\t19.0\t10282\t10171\n",
      "2016-02-04 18:44:19+00:00\t2016-02-04 18:46:00+00:00\t0.28\t3.5\t10110\t10110\n",
      "2016-02-17 17:13:57+00:00\t2016-02-17 17:17:55+00:00\t0.7\t5.0\t10103\t10023\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mWe can use the 'trip_distance' column instead of 'duration'.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT MAX(trip_distance) FROM trips\u001b[0m\u001b[36;1m\u001b[1;3m[(30.6,)]\u001b[0m\u001b[32;1m\u001b[1;3m30.6 is the longest trip distance.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT tpep_pickup_datetime, tpep_dropoff_datetime FROM trips WHERE trip_distance = 30.6\u001b[0m\u001b[36;1m\u001b[1;3m[(datetime.datetime(2016, 2, 22, 21, 17, 27), datetime.datetime(2016, 2, 22, 22, 0, 58))]\u001b[0m\u001b[32;1m\u001b[1;3m30.6 is the longest trip distance and it took 43 minutes and 31 seconds.\n",
      "Final Answer: The longest trip distance is 30.6 and it took 43 minutes and 31 seconds.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the longest trip distance and how long did it take?',\n",
       " 'output': 'The longest trip distance is 30.6 and it took 43 minutes and 31 seconds.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What is the longest trip distance and how long did it take?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1484593-3f9d-4045-a943-89a449e65eed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the sql_db_query checker to make sure my query is correct\n",
      "Action: sql_db_query_checker\n",
      "Action Input: SELECT zipcode FROM trips ORDER BY fare DESC LIMIT 1\u001b[0m\u001b[36;1m\u001b[1;3m\n",
      "SELECT zipcode \n",
      "FROM trips \n",
      "WHERE zipcode NOT IN (NULL) \n",
      "ORDER BY fare DESC \n",
      "LIMIT 1\u001b[0m\u001b[32;1m\u001b[1;3m I should use the sql_db_query tool to execute my query and get the result\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT zipcode FROM trips ORDER BY fare DESC LIMIT 1\u001b[0m\u001b[36;1m\u001b[1;3mError: (databricks.sql.exc.ServerOperationError) [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `zipcode` cannot be resolved. Did you mean one of the following? [`pickup_zip`, `dropoff_zip`, `fare_amount`, `trip_distance`, `tpep_pickup_datetime`]. SQLSTATE: 42703; line 1 pos 7\n",
      "[SQL: SELECT zipcode FROM trips ORDER BY fare DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/4xp6)\u001b[0m\u001b[32;1m\u001b[1;3m I should use the sql_db_schema tool to check which table has the correct column name\n",
      "Action: sql_db_schema\n",
      "Action Input: trips\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE trips (\n",
      "\ttpep_pickup_datetime TIMESTAMP, \n",
      "\ttpep_dropoff_datetime TIMESTAMP, \n",
      "\ttrip_distance FLOAT, \n",
      "\tfare_amount FLOAT, \n",
      "\tpickup_zip INT, \n",
      "\tdropoff_zip INT\n",
      ") USING DELTA\n",
      "TBLPROPERTIES('delta.feature.allowColumnDefaults' = 'enabled')\n",
      "\n",
      "/*\n",
      "3 rows from trips table:\n",
      "tpep_pickup_datetime\ttpep_dropoff_datetime\ttrip_distance\tfare_amount\tpickup_zip\tdropoff_zip\n",
      "2016-02-14 16:52:13+00:00\t2016-02-14 17:16:04+00:00\t4.94\t19.0\t10282\t10171\n",
      "2016-02-04 18:44:19+00:00\t2016-02-04 18:46:00+00:00\t0.28\t3.5\t10110\t10110\n",
      "2016-02-17 17:13:57+00:00\t2016-02-17 17:17:55+00:00\t0.7\t5.0\t10103\t10023\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m I should use the sql_db_query tool again with the correct column name\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT pickup_zip FROM trips ORDER BY fare DESC LIMIT 1\u001b[0m\u001b[36;1m\u001b[1;3mError: (databricks.sql.exc.ServerOperationError) [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `fare` cannot be resolved. Did you mean one of the following? [`pickup_zip`]. SQLSTATE: 42703; line 1 pos 38\n",
      "[SQL: SELECT pickup_zip FROM trips ORDER BY fare DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/4xp6)\u001b[0m\u001b[32;1m\u001b[1;3m I should use the sql_db_schema tool again to check for any other column names that might be relevant\n",
      "Action: sql_db_schema\n",
      "Action Input: trips\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE trips (\n",
      "\ttpep_pickup_datetime TIMESTAMP, \n",
      "\ttpep_dropoff_datetime TIMESTAMP, \n",
      "\ttrip_distance FLOAT, \n",
      "\tfare_amount FLOAT, \n",
      "\tpickup_zip INT, \n",
      "\tdropoff_zip INT\n",
      ") USING DELTA\n",
      "TBLPROPERTIES('delta.feature.allowColumnDefaults' = 'enabled')\n",
      "\n",
      "/*\n",
      "3 rows from trips table:\n",
      "tpep_pickup_datetime\ttpep_dropoff_datetime\ttrip_distance\tfare_amount\tpickup_zip\tdropoff_zip\n",
      "2016-02-14 16:52:13+00:00\t2016-02-14 17:16:04+00:00\t4.94\t19.0\t10282\t10171\n",
      "2016-02-04 18:44:19+00:00\t2016-02-04 18:46:00+00:00\t0.28\t3.5\t10110\t10110\n",
      "2016-02-17 17:13:57+00:00\t2016-02-17 17:17:55+00:00\t0.7\t5.0\t10103\t10023\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m I should use the sql_db_query tool one more time with the correct column name\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT pickup_zip FROM trips ORDER BY fare_amount DESC LIMIT 1\u001b[0m\u001b[36;1m\u001b[1;3m[(10013,)]\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 10013\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'find out the zipcode of the trip with the highest fare',\n",
       " 'output': '10013'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"find out the zipcode of the trip with the highest fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4afadc2-0a5f-4df4-9a36-d776be532d3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "189b01f6-54db-4458-8f5f-d8e54f3a388e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_openai import OpenAI, AzureChatOpenAI\n",
    "\n",
    "db = SQLDatabase.from_databricks(catalog=\"samples\", schema=\"nyctaxi\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    api_key=\"\",\n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint=\"\",\n",
    "    model=\"gpt4o\"\n",
    ")\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "agent = create_sql_agent(llm=llm, toolkit=toolkit, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc313533-a333-4b5d-ae27-9be5bcbb7df9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to determine which tables are present in the database and identify the one that contains information about trips, their distances, and durations.\n",
      "\n",
      "Action: List all tables in the database.\n",
      "Action Input: \"\"\u001b[0mList all tables in the database. is not a valid tool, try one of [sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker].\u001b[32;1m\u001b[1;3mI should use the correct tool to list all tables in the database.\n",
      "\n",
      "Action: sql_db_list_tables\n",
      "Action Input: \"\"\u001b[0m\u001b[38;5;200m\u001b[1;3mtrips\u001b[0m\u001b[32;1m\u001b[1;3mThe database contains a table named \"trips.\" I need to inspect the schema of the \"trips\" table to determine which columns are available, particularly those related to trip distances and durations.\n",
      "\n",
      "Action: sql_db_schema\n",
      "Action Input: trips\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE trips (\n",
      "\ttpep_pickup_datetime TIMESTAMP, \n",
      "\ttpep_dropoff_datetime TIMESTAMP, \n",
      "\ttrip_distance FLOAT, \n",
      "\tfare_amount FLOAT, \n",
      "\tpickup_zip INT, \n",
      "\tdropoff_zip INT\n",
      ") USING DELTA\n",
      "TBLPROPERTIES('delta.feature.allowColumnDefaults' = 'enabled')\n",
      "\n",
      "/*\n",
      "3 rows from trips table:\n",
      "tpep_pickup_datetime\ttpep_dropoff_datetime\ttrip_distance\tfare_amount\tpickup_zip\tdropoff_zip\n",
      "2016-02-14 16:52:13+00:00\t2016-02-14 17:16:04+00:00\t4.94\t19.0\t10282\t10171\n",
      "2016-02-04 18:44:19+00:00\t2016-02-04 18:46:00+00:00\t0.28\t3.5\t10110\t10110\n",
      "2016-02-17 17:13:57+00:00\t2016-02-17 17:17:55+00:00\t0.7\t5.0\t10103\t10023\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mThe `trips` table contains columns that are relevant to our query:\n",
      "\n",
      "- `trip_distance` (FLOAT)\n",
      "- `tpep_pickup_datetime` (TIMESTAMP)\n",
      "- `tpep_dropoff_datetime` (TIMESTAMP)\n",
      "\n",
      "To find the longest trip distance and its duration, I will:\n",
      "\n",
      "1. Identify the maximum trip distance.\n",
      "2. Calculate the time difference between `tpep_pickup_datetime` and `tpep_dropoff_datetime` for the record with the maximum trip distance.\n",
      "\n",
      "Let's proceed with these steps.\n",
      "\n",
      "Action: sql_db_query_checker\n",
      "Action Input: \"SELECT trip_distance, tpep_dropoff_datetime - tpep_pickup_datetime AS duration FROM trips ORDER BY trip_distance DESC LIMIT 1;\"\u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT trip_distance, tpep_dropoff_datetime - tpep_pickup_datetime AS duration \n",
      "FROM trips \n",
      "ORDER BY trip_distance DESC \n",
      "LIMIT 1;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mI will now execute the query to find the longest trip distance and its duration.\n",
      "\n",
      "Action: sql_db_query\n",
      "Action Input: \"SELECT trip_distance, tpep_dropoff_datetime - tpep_pickup_datetime AS duration FROM trips ORDER BY trip_distance DESC LIMIT 1;\"\u001b[0m\u001b[36;1m\u001b[1;3m[(30.6, '0 00:43:31.000000000')]\u001b[0m\u001b[32;1m\u001b[1;3mThe longest trip distance is 30.6 units, and it took 43 minutes and 31 seconds.\n",
      "\n",
      "Final Answer: The longest trip distance is 30.6 units, and it took 43 minutes and 31 seconds.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the longest trip distance and how long did it take?',\n",
       " 'output': 'The longest trip distance is 30.6 units, and it took 43 minutes and 31 seconds.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What is the longest trip distance and how long did it take?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851fdf04-d2f7-4adb-8c02-6e9faeaaf627",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the zipcode of the trip with the highest fare, I need to:\n",
      "1. List all the tables in the database to identify where trip information is stored.\n",
      "2. Identify the schema of the relevant table to find the fields related to fare and zipcode.\n",
      "3. Write and check an SQL query to find the trip with the highest fare and retrieve its associated zipcode.\n",
      "\n",
      "Let's start by listing all the tables in the database.\n",
      "\n",
      "Action: sql_db_list_tables\n",
      "Action Input: \"\"\u001b[0m\u001b[38;5;200m\u001b[1;3mtrips\u001b[0m\u001b[32;1m\u001b[1;3mThe database contains a table named \"trips\". Next, I need to examine the schema of the \"trips\" table to identify the fields related to fare and zipcode.\n",
      "\n",
      "Action: sql_db_schema\n",
      "Action Input: \"trips\"\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE trips (\n",
      "\ttpep_pickup_datetime TIMESTAMP, \n",
      "\ttpep_dropoff_datetime TIMESTAMP, \n",
      "\ttrip_distance FLOAT, \n",
      "\tfare_amount FLOAT, \n",
      "\tpickup_zip INT, \n",
      "\tdropoff_zip INT\n",
      ") USING DELTA\n",
      "TBLPROPERTIES('delta.feature.allowColumnDefaults' = 'enabled')\n",
      "\n",
      "/*\n",
      "3 rows from trips table:\n",
      "tpep_pickup_datetime\ttpep_dropoff_datetime\ttrip_distance\tfare_amount\tpickup_zip\tdropoff_zip\n",
      "2016-02-14 16:52:13+00:00\t2016-02-14 17:16:04+00:00\t4.94\t19.0\t10282\t10171\n",
      "2016-02-04 18:44:19+00:00\t2016-02-04 18:46:00+00:00\t0.28\t3.5\t10110\t10110\n",
      "2016-02-17 17:13:57+00:00\t2016-02-17 17:17:55+00:00\t0.7\t5.0\t10103\t10023\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mThe \"trips\" table contains the necessary fields for finding the trip with the highest fare: `fare_amount`, `pickup_zip`, and `dropoff_zip`.\n",
      "\n",
      "To find the zipcode of the trip with the highest fare, I need to:\n",
      "1. Identify the maximum fare from the `fare_amount` column.\n",
      "2. Retrieve the corresponding `pickup_zip` and/or `dropoff_zip` for that trip.\n",
      "\n",
      "I'll write and check an SQL query to find the trip with the highest fare and retrieve its associated zipcode(s).\n",
      "\n",
      "Action: sql_db_query_checker\n",
      "Action Input: \"SELECT pickup_zip, dropoff_zip FROM trips ORDER BY fare_amount DESC LIMIT 1;\"\u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT pickup_zip, dropoff_zip \n",
      "FROM trips \n",
      "ORDER BY fare_amount DESC \n",
      "LIMIT 1;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe SQL query has been verified as correct. Now, I will execute this query to find the zipcode of the trip with the highest fare.\n",
      "\n",
      "Action: sql_db_query\n",
      "Action Input: \"SELECT pickup_zip, dropoff_zip FROM trips ORDER BY fare_amount DESC LIMIT 1;\"\u001b[0m\u001b[36;1m\u001b[1;3m[(10013, 7008)]\u001b[0m\u001b[32;1m\u001b[1;3mThe query execution has returned the zipcodes for the trip with the highest fare. The `pickup_zip` is `10013`, and the `dropoff_zip` is `7008`.\n",
      "\n",
      "Final Answer: The zipcode of the trip with the highest fare is `10013` for pickup and `7008` for dropoff.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'find out the zipcode of the trip with the highest fare',\n",
       " 'output': 'The zipcode of the trip with the highest fare is `10013` for pickup and `7008` for dropoff.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"find out the zipcode of the trip with the highest fare\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Databricks Text to SQL Database Agent using Langchain",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
